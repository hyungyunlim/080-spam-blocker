#!/usr/bin/env python3
"""
M1 ë§¥ë¯¸ë‹ˆìš© STT ë¶„ì„ ì„œë²„
ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ì „ì†¡ëœ ìŒì„± íŒŒì¼ì„ M1ì˜ Neural Engineìœ¼ë¡œ ë¹ ë¥´ê²Œ ë¶„ì„
"""

import os
import json
import time
import whisper
import tempfile
import threading
from datetime import datetime
from flask import Flask, request, jsonify, send_file
from werkzeug.utils import secure_filename
import re

# ffmpeg ê²½ë¡œ ì„¤ì • (M1 Mac)
os.environ['PATH'] = '/opt/homebrew/bin:' + os.environ.get('PATH', '')

app = Flask(__name__)

# ì„¤ì •
UPLOAD_FOLDER = '/tmp/stt_uploads'
RESULTS_FOLDER = '/tmp/stt_results'
ALLOWED_EXTENSIONS = {'wav', 'mp3', 'flac', 'm4a'}
MAX_CONTENT_LENGTH = 50 * 1024 * 1024  # 50MB

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = MAX_CONTENT_LENGTH

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULTS_FOLDER, exist_ok=True)

# Whisper ëª¨ë¸ ë¡œë“œ (M1 ìµœì í™” - small ëª¨ë¸ ì‚¬ìš©)
print("Loading Whisper model on M1 Mac...")
model = whisper.load_model("small")  # baseì—ì„œ smallë¡œ í•œ ë‹¨ê³„ ì—…ê·¸ë ˆì´ë“œ
print("Whisper SMALL model loaded successfully! (ì •í™•ë„ í–¥ìƒ)")

# ì§„í–‰ ìƒí™© ì¶”ì 
analysis_progress = {}

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def detect_success_keywords(text):
    """ìˆ˜ì‹ ê±°ë¶€ ì„±ê³µ í‚¤ì›Œë“œ ê²€ì¶œ (ê°œì„ ëœ íŒ¨í„´)"""
    # ë” í¬ê´„ì ì¸ ì„±ê³µ íŒ¨í„´
    success_patterns = [
        # ì§ì ‘ì ì¸ ì™„ë£Œ í‘œí˜„
        r'ìˆ˜ì‹ ê±°ë¶€.*ì™„ë£Œ',
        r'ìˆ˜ì‹ ê±°ë¶€.*ì²˜ë¦¬.*ì™„ë£Œ',
        r'ìˆ˜ì‹ ê±°ë¶€.*ë˜ì—ˆìŠµë‹ˆë‹¤',
        r'ì°¨ë‹¨.*ì™„ë£Œ',
        r'ì°¨ë‹¨.*ë˜ì—ˆìŠµë‹ˆë‹¤',
        r'í•´ì§€.*ì™„ë£Œ',
        r'í•´ì§€.*ë˜ì—ˆìŠµë‹ˆë‹¤',
        r'ì²˜ë¦¬.*ì™„ë£Œ',
        r'í™•ì¸.*ì™„ë£Œ',
        r'ì ‘ìˆ˜.*ì™„ë£Œ',
        r'ë“±ë¡.*ì™„ë£Œ',
        
        # ê°„ì ‘ì ì¸ ì„±ê³µ í‘œí˜„
        r'ì •ìƒ.*ì²˜ë¦¬',
        r'ì„±ê³µ.*ì²˜ë¦¬',
        r'ì™„ë£Œ.*ì²˜ë¦¬',
        r'ì‹ ì²­.*ì™„ë£Œ',
        r'ìš”ì²­.*ì™„ë£Œ',
        r'ë“±ë¡.*ì„±ê³µ',
        
        # ê°ì‚¬ í‘œí˜„ (ë³´í†µ ì„±ê³µ í›„)
        r'ê°ì‚¬í•©ë‹ˆë‹¤.*ì™„ë£Œ',
        r'ì´ìš©.*ê°ì‚¬',
        r'ì™„ë£Œ.*ê°ì‚¬',
        
        # í™•ì¸ ì½”ë“œë‚˜ ë²ˆí˜¸ ì œê³µ
        r'í™•ì¸ë²ˆí˜¸.*[0-9]+',
        r'ì ‘ìˆ˜ë²ˆí˜¸.*[0-9]+',
        r'ì²˜ë¦¬ë²ˆí˜¸.*[0-9]+'
    ]
    
    text_clean = re.sub(r'\s+', '', text.lower())
    
    for pattern in success_patterns:
        if re.search(pattern, text_clean):
            return True, pattern
    
    return False, None

def analyze_audio_file(filepath, call_id):
    """ìŒì„± íŒŒì¼ ë¶„ì„ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)"""
    try:
        start_time = time.time()
        
        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        analysis_progress[call_id] = {
            'status': 'processing',
            'progress': 10,
            'message': 'ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì¤‘...'
        }
        
        # Whisperë¡œ ìŒì„± ì¸ì‹
        analysis_progress[call_id]['progress'] = 30
        analysis_progress[call_id]['message'] = 'STT ë³€í™˜ ì¤‘...'
        
        result = model.transcribe(filepath, language='ko')
        transcription = result["text"].strip()
        
        analysis_progress[call_id]['progress'] = 70
        analysis_progress[call_id]['message'] = 'í‚¤ì›Œë“œ ë¶„ì„ ì¤‘...'
        
        # í‚¤ì›Œë“œ ë¶„ì„
        is_success, matched_pattern = detect_success_keywords(transcription)
        
        processing_time = time.time() - start_time
        
        if is_success:
            status = 'success'
            confidence = 85
            reason = f'ìˆ˜ì‹ ê±°ë¶€ ì„±ê³µ íŒ¨í„´ ë°œê²¬: {matched_pattern}'
        else:
            status = 'failed'
            confidence = 30
            reason = 'ìˆ˜ì‹ ê±°ë¶€ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ'
        
        # ê²°ê³¼ ì €ì¥
        result_data = {
            'call_id': call_id,
            'transcription': transcription,
            'status': status,
            'confidence': confidence,
            'reason': reason,
            'processing_time': round(processing_time, 2),
            'timestamp': datetime.now().isoformat(),
            'model': 'whisper-base-m1',
            'pattern_hint': matched_pattern if is_success else None
        }
        
        # ì§„í–‰ ìƒí™© ì™„ë£Œ ì—…ë°ì´íŠ¸
        analysis_progress[call_id] = {
            'status': 'completed',
            'progress': 100,
            'message': 'ë¶„ì„ ì™„ë£Œ',
            'result': result_data
        }
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        result_file = os.path.join(RESULTS_FOLDER, f'{call_id}.json')
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"Analysis completed for {call_id}: {status} ({processing_time:.2f}s)")
        
    except Exception as e:
        error_msg = str(e)
        print(f"Analysis error for {call_id}: {error_msg}")
        
        analysis_progress[call_id] = {
            'status': 'error',
            'progress': 0,
            'message': f'ë¶„ì„ ì˜¤ë¥˜: {error_msg}',
            'result': {
                'status': 'failed',
                'confidence': 0,
                'reason': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_msg}'
            }
        }

@app.route('/health')
def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        'status': 'healthy',
        'service': 'M1-STT-Analyzer',
        'model': 'whisper-base',
        'timestamp': datetime.now().isoformat()
    })

@app.route('/analyze', methods=['POST'])
def analyze():
    """ìŒì„± íŒŒì¼ ë¶„ì„ ìš”ì²­"""
    if 'audio_file' not in request.files:
        return jsonify({'error': 'No audio file provided'}), 400
    
    file = request.files['audio_file']
    call_id = request.form.get('call_id', 'unknown')
    
    if file.filename == '':
        return jsonify({'error': 'No file selected'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': 'File type not allowed'}), 400
    
    try:
        # íŒŒì¼ ì €ì¥
        filename = secure_filename(f"{call_id}_{file.filename}")
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹œì‘
        thread = threading.Thread(target=analyze_audio_file, args=(filepath, call_id))
        thread.start()
        
        return jsonify({
            'message': 'ë¶„ì„ ì‹œì‘ë¨',
            'call_id': call_id,
            'status': 'processing'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/progress/<call_id>')
def get_progress(call_id):
    """ë¶„ì„ ì§„í–‰ ìƒí™© ì¡°íšŒ"""
    if call_id not in analysis_progress:
        return jsonify({'error': 'Analysis not found'}), 404
    
    return jsonify(analysis_progress[call_id])

@app.route('/result/<call_id>')
def get_result(call_id):
    """ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    result_file = os.path.join(RESULTS_FOLDER, f'{call_id}.json')
    
    if not os.path.exists(result_file):
        return jsonify({'error': 'Result not found'}), 404
    
    with open(result_file, 'r', encoding='utf-8') as f:
        result = json.load(f)
    
    return jsonify(result)

@app.route('/status')
def server_status():
    """ì„œë²„ ìƒíƒœ ë° í†µê³„"""
    active_analyses = len([p for p in analysis_progress.values() if p['status'] == 'processing'])
    completed_analyses = len([p for p in analysis_progress.values() if p['status'] == 'completed'])
    
    return jsonify({
        'server': 'M1-STT-Analyzer',
        'model': 'whisper-base',
        'active_analyses': active_analyses,
        'completed_analyses': completed_analyses,
        'total_requests': len(analysis_progress),
        'uptime': time.time() - app.start_time if hasattr(app, 'start_time') else 0
    })

if __name__ == '__main__':
    app.start_time = time.time()
    print("ğŸš€ M1 STT Analysis Server starting...")
    print("ğŸ“± Optimized for Apple Silicon Neural Engine")
    print("ğŸ¯ Listening on 0.0.0.0:8080")
    
    # M1 ë§¥ë¯¸ë‹ˆì—ì„œ ì‹¤í–‰
    app.run(host='0.0.0.0', port=8080, debug=False, threaded=True)